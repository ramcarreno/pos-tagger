{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a55e0a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from functools import reduce\n",
    "\n",
    "import os\n",
    "import sys\n",
    "root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(root)\n",
    "\n",
    "from validation import get_error_propagation_prob, get_accuracy, get_precision, get_recall, get_f1\n",
    "from src.scrapper import parse_conllu_file\n",
    "from src.tagger import HiddenMarkovModel, HiddenMarkovModelTagger\n",
    "from src.visualization import plot_viterbi_path_binary, plot_viterbi_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c7c20e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data\n",
    "train = parse_conllu_file(filepath=\"../datasets/en_gum-ud-train.conllu\")\n",
    "test = parse_conllu_file(filepath=\"../datasets/en_gum-ud-test.conllu\")\n",
    "tagger = HiddenMarkovModel(corpus=train).train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a641e21c-a7db-488d-ae67-acd594b1c131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24769617425300194\n"
     ]
    }
   ],
   "source": [
    "# Compute prediction data\n",
    "test_predictions = tagger.predict(corpus=test)\n",
    "print(get_error_propagation_prob(test, test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed21bebc-61df-42ba-911c-884431040595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 179    0    0    0    0    0    0    0   69    0    0    0    2    0    0    0   10    0]\n",
      " [   0  881    2   24    0    0    0    0  346    0    0    0    7    0    0    0   67    0]\n",
      " [   0    0 2029    3    0    2    0    0    7    0    0    3    0    0    2    0    1    0]\n",
      " [   0   52   85  652    0    0   19    0   67    0    0   27    8    0    0    0   15    0]\n",
      " [   0    0    0    0  812    0    0    0   10    0    0    0    0    0    0    0  104    0]\n",
      " [   0    0    0    2    0  680   18    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    1    0    0    0    3 1660    0    2    0    0   55    0    0    0    0    0    0]\n",
      " [   0    2   12   30    0    0    5   75   14    0    0    0    1    0    0    0    9    0]\n",
      " [   0   13    0    5    1    0    1    0 3290    0    0    0   48    0    0    0  150    0]\n",
      " [   0    0    0    0    0    0    0    0  144  237    0    1   17    0    0    0    2    0]\n",
      " [   0    0  222    0   71    0    1    0    2    0  122    0    0    1    0    0    1    0]\n",
      " [   0    0    0    1    0    0   18    0    2    0    1 1412    0    0    0    0    0    0]\n",
      " [   0   40    0    0    0    0    0    0  942    0    0    2  396    0    0    0   32    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0 2540    0    0    0    0]\n",
      " [   0    0  104    8    0    1    0    0    3    0    0   51    0    0   82    0    1    0]\n",
      " [   0    0    0    0    0    0    0    0    5    0    0    0    0   21    0    8    0    0]\n",
      " [   0   20    1    2   88    0    0    0  458    0    0    0   14    0    0    0 1507    0]\n",
      " [   0    0    1    0    0    0    0    0   15    0    0    0    7    0    0    0    0    5]]\n"
     ]
    }
   ],
   "source": [
    "# Compute confusion matrix\n",
    "tagset = tagger.tagset  # read corpus tagset\n",
    "cm = tagger.get_confusion_matrix(test, test_predictions)\n",
    "\n",
    "# Format matrix for pretty printing\n",
    "cm_formatted = np.array2string(cm, precision=0, separator=' ', suppress_small=True, max_line_width=100)\n",
    "print(cm_formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "643d8be7-9f32-41ff-bfce-7b16a0c41af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL ACCURACY\n",
      "--------------\n",
      "Model accuracy: 0.8213\n",
      "\n",
      "MODEL PRECISION\n",
      "---------------\n",
      "_: 1.0000 over 179 predictions.\n",
      "adj: 0.8731 over 1009 predictions.\n",
      "adp: 0.8261 over 2456 predictions.\n",
      "adv: 0.8968 over 727 predictions.\n",
      "aux: 0.8354 over 972 predictions.\n",
      "cconj: 0.9913 over 686 predictions.\n",
      "det: 0.9640 over 1722 predictions.\n",
      "intj: 1.0000 over 75 predictions.\n",
      "noun: 0.6120 over 5376 predictions.\n",
      "num: 1.0000 over 237 predictions.\n",
      "part: 0.9919 over 123 predictions.\n",
      "pron: 0.9104 over 1551 predictions.\n",
      "propn: 0.7920 over 500 predictions.\n",
      "punct: 0.9914 over 2562 predictions.\n",
      "sconj: 0.9762 over 84 predictions.\n",
      "sym: 1.0000 over 8 predictions.\n",
      "verb: 0.7936 over 1899 predictions.\n",
      "x: 1.0000 over 5 predictions.\n",
      "\n",
      "Weighted average model micro precision: 0.8459\n",
      "Average model macro precision: 0.9141\n",
      "\n",
      "MODEL RECALL\n",
      "------------\n",
      "_: 0.6885 over 260 predictions.\n",
      "adj: 0.6639 over 1327 predictions.\n",
      "adp: 0.9912 over 2047 predictions.\n",
      "adv: 0.7049 over 925 predictions.\n",
      "aux: 0.8769 over 926 predictions.\n",
      "cconj: 0.9714 over 700 predictions.\n",
      "det: 0.9646 over 1721 predictions.\n",
      "intj: 0.5068 over 148 predictions.\n",
      "noun: 0.9379 over 3508 predictions.\n",
      "num: 0.5910 over 401 predictions.\n",
      "part: 0.2905 over 420 predictions.\n",
      "pron: 0.9847 over 1434 predictions.\n",
      "propn: 0.2805 over 1412 predictions.\n",
      "punct: 1.0000 over 2540 predictions.\n",
      "sconj: 0.3280 over 250 predictions.\n",
      "sym: 0.2353 over 34 predictions.\n",
      "verb: 0.7211 over 2090 predictions.\n",
      "x: 0.1786 over 28 predictions.\n",
      "\n",
      "Weighted average model micro recall: 0.8818\n",
      "Average model macro recall: 0.6620\n",
      "\n",
      "MODEL F1\n",
      "------------\n",
      "Model micro F1: 0.8639\n",
      "Model macro F1: 0.7880\n"
     ]
    }
   ],
   "source": [
    "# Accuracy calculations\n",
    "print(\"MODEL ACCURACY\")\n",
    "print(\"--------------\")\n",
    "\n",
    "acc = get_accuracy(cm)\n",
    "print(f\"Model accuracy: {acc:.4f}\")\n",
    "print()\n",
    "\n",
    "\n",
    "# Precision calculations\n",
    "print(\"MODEL PRECISION\")\n",
    "print(\"---------------\")\n",
    "\n",
    "precs, p_preds, p_micro, p_macro = get_precision(cm)\n",
    "prec_data = zip(tagset, precs, p_preds)\n",
    "for tag in prec_data:  # iterate over all classes\n",
    "    print(f\"{tag[0]}: {tag[1]:.4f} over {int(tag[2])} predictions.\")\n",
    "\n",
    "print(f\"\\nWeighted average model micro precision: {p_micro:.4f}\")\n",
    "print(f\"Average model macro precision: {p_macro:.4f}\")\n",
    "print()\n",
    "\n",
    "\n",
    "# Recall calculations\n",
    "print(\"MODEL RECALL\")\n",
    "print(\"------------\")\n",
    "\n",
    "recalls, r_preds, r_micro, r_macro = get_recall(cm)\n",
    "recall_data = zip(tagset, recalls, r_preds)\n",
    "for tag in recall_data:  # iterate over all classes\n",
    "    print(f\"{tag[0]}: {tag[1]:.4f} over {int(tag[2])} predictions.\")\n",
    "\n",
    "print(f\"\\nWeighted average model micro recall: {r_micro:.4f}\")\n",
    "print(f\"Average model macro recall: {r_macro:.4f}\")\n",
    "print()\n",
    "\n",
    "# F1 calculations\n",
    "print(\"MODEL F1\")\n",
    "print(\"------------\")\n",
    "f1s, predictions, micro_f1, macro_f1 = get_f1(cm)\n",
    "print(f\"Model micro F1: {micro_f1:.4f}\")\n",
    "print(f\"Model macro F1: {macro_f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
