{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import HiddenMarkovModelTagger as ExternalHMM\n",
    "from src.tagger import HiddenMarkovModelTrainer as LocalHMM\n",
    "\n",
    "from src.scrapper import parse_conllu_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we analyse the performance of our algorithm in terms of speed and space (computationally-wise).\n",
    "We will perform a set of experiments in which we will compare the performance of our implementation and the nltk version of the HMM.\n",
    "\n",
    "In this analysis, we don't expect to prove that our algorithm is better since we are well aware that there are lots of optimizations that big libraries such as nltk have included and we lack. However, it is an interesting exercise and a good way to reflect what our weaknesses and strengths are, as well as thinking hypothetical future work and improvements that could be done if this project went further.\n",
    "\n",
    "-> It is recommended not to execute again the cells below since results may vary slightly according to the architecture where the code is ran. However, the magnitudes and proportions between experiments should be preserved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length size S = 10\n",
      "Length size M = 6561\n",
      "Length size L = 13123\n",
      "Length size XL = 131230\n"
     ]
    }
   ],
   "source": [
    "dataset = parse_conllu_file(filepath=\"../datasets/ca_ancora-ud-train.conllu\")\n",
    "\n",
    "s_dataset = dataset[:10]\n",
    "m_dataset = dataset[:int(len(dataset)/2)]\n",
    "l_dataset = dataset\n",
    "xl_dataset = dataset*10\n",
    "\n",
    "datasets = {\n",
    "    'S': s_dataset, \n",
    "    'M': m_dataset, \n",
    "    'L': l_dataset, \n",
    "    'XL': xl_dataset\n",
    "}\n",
    "\n",
    "for name, data in datasets.items():\n",
    "    print(f'Length size {name} = {len(data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Analysis\n",
    "\n",
    "From now on, we will refer to:\n",
    "* The models trained using the nltk library as `external model`.\n",
    "* The models trained using our implementation as the `local implementation`\n",
    "* The models trained with the different sizes of data as `S`, `M`, `L`, `XL`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "349 µs ± 5.82 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "157 ms ± 178 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "305 ms ± 450 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "3.03 s ± 4.07 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# external model\n",
    "external_s_time = %timeit -o ExternalHMM.train(s_dataset)\n",
    "external_m_time = %timeit -o ExternalHMM.train(m_dataset)\n",
    "external_l_time = %timeit -o ExternalHMM.train(l_dataset)\n",
    "external_xl_time = %timeit -o ExternalHMM.train(xl_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249 µs ± 851 ns per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "105 ms ± 468 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "206 ms ± 3.74 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "1.99 s ± 5.01 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# local\n",
    "local_s_model = %timeit -o LocalHMM(s_dataset).train()\n",
    "local_m_model = %timeit -o LocalHMM(m_dataset).train()\n",
    "local_l_model = %timeit -o LocalHMM(l_dataset).train()\n",
    "local_xl_model = %timeit -o LocalHMM(xl_dataset).train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = parse_conllu_file(filepath=\"../datasets/ca_ancora-ud-test.conllu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_s_model = ExternalHMM.train(s_dataset)\n",
    "external_xl_model = ExternalHMM.train(xl_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra - Memory Analysis Approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
