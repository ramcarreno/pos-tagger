{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import HiddenMarkovModelTagger as ExternalHMM\n",
    "from src.tagger import HiddenMarkovModel as LocalHMM\n",
    "\n",
    "from src.scrapper import parse_conllu_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we analyse the performance of our algorithm in terms of speed and space (computationally-wise).\n",
    "We will perform a set of experiments in which we will compare the performance of our implementation and the nltk version of the HMM.\n",
    "\n",
    "In this analysis, we don't expect to prove that our algorithm is better since we are well aware that there are lots of optimizations that big libraries such as nltk have included and we lack. However, it is an interesting exercise and a good way to reflect what our weaknesses and strengths are, as well as thinking hypothetical future work and improvements that could be done if this project went further.\n",
    "\n",
    "-> It is recommended not to execute again the cells below since results may vary slightly according to the architecture where the code is ran. However, the magnitudes and proportions between experiments should be preserved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length size S = 10\n",
      "Length size M = 6561\n",
      "Length size L = 13123\n",
      "Length size XL = 131230\n"
     ]
    }
   ],
   "source": [
    "dataset = parse_conllu_file(filepath=\"../datasets/ca_ancora-ud-train.conllu\")\n",
    "\n",
    "s_dataset = dataset[:10]\n",
    "m_dataset = dataset[:int(len(dataset)/2)]\n",
    "l_dataset = dataset\n",
    "xl_dataset = dataset*10\n",
    "\n",
    "datasets = {\n",
    "    'S': s_dataset, \n",
    "    'M': m_dataset, \n",
    "    'L': l_dataset, \n",
    "    'XL': xl_dataset\n",
    "}\n",
    "\n",
    "for name, data in datasets.items():\n",
    "    print(f'Length size {name} = {len(data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Analysis\n",
    "\n",
    "From now on, we will refer to:\n",
    "* The models trained using the nltk library as `external model`.\n",
    "* The models trained using our implementation as the `local implementation`\n",
    "* The models trained with the different sizes of data as `S`, `M`, `L`, `XL`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "355 µs ± 1.75 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "162 ms ± 2.35 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "309 ms ± 2.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "3.11 s ± 46.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# external model\n",
    "external_s_time = %timeit -o ExternalHMM.train(s_dataset)\n",
    "external_m_time = %timeit -o ExternalHMM.train(m_dataset)\n",
    "external_l_time = %timeit -o ExternalHMM.train(l_dataset)\n",
    "external_xl_time = %timeit -o ExternalHMM.train(xl_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256 µs ± 2.98 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "108 ms ± 2.23 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "217 ms ± 7.02 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "2.03 s ± 20.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# local\n",
    "local_s_model = %timeit -o LocalHMM(s_dataset).train()\n",
    "local_m_model = %timeit -o LocalHMM(m_dataset).train()\n",
    "local_l_model = %timeit -o LocalHMM(l_dataset).train()\n",
    "local_xl_model = %timeit -o LocalHMM(xl_dataset).train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = parse_conllu_file(filepath=\"../datasets/ca_ancora-ud-test.conllu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_s_model = ExternalHMM.train(s_dataset)\n",
    "external_xl_model = ExternalHMM.train(xl_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory Analysis Approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carbon Print Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model is a very simple approach that requires few reosurces to train and predict. However, it is interesting to check out the carbon footprint it may generate, if only for the sake of curiosity. \n",
    "\n",
    "In this section, we use a library that is in charge of tracking the emissions a function generates. Since the element we will use it's a decorator and we don't want to touch our source code, we have created a mock function that will basically call any method we send as parameter with the corresponding arguments and keyword arguments.\n",
    "\n",
    "This way, we can check our carbon footprint without affecting the actual code.\n",
    "\n",
    "⚠️ Note that the conclusions drawn in this section can be misleading if the code is re-run in another computer or with other data, so they must be taken as orientative and prone to change ⚠️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codecarbon import track_emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@track_emissions()\n",
    "def compute_emissions(function_to_track: callable, *args, **kwargs):\n",
    "    return function_to_track(*args,**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 23:23:11] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 23:23:11] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 23:23:11] No GPU found.\n",
      "[codecarbon INFO @ 23:23:11] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 23:23:11] No CPU tracking mode found. Falling back on CPU constant mode.\n",
      "[codecarbon INFO @ 23:23:12] CPU Model on constant consumption mode: Apple M1\n",
      "[codecarbon INFO @ 23:23:12] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 23:23:12]   Platform system: macOS-13.5.2-arm64-arm-64bit\n",
      "[codecarbon INFO @ 23:23:12]   Python version: 3.11.6\n",
      "[codecarbon INFO @ 23:23:12]   CodeCarbon version: 2.3.1\n",
      "[codecarbon INFO @ 23:23:12]   Available RAM : 16.000 GB\n",
      "[codecarbon INFO @ 23:23:12]   CPU count: 8\n",
      "[codecarbon INFO @ 23:23:12]   CPU model: Apple M1\n",
      "[codecarbon INFO @ 23:23:12]   GPU count: None\n",
      "[codecarbon INFO @ 23:23:12]   GPU model: None\n",
      "[codecarbon INFO @ 23:23:15] \n",
      "Graceful stopping: collecting and writing information.\n",
      "Please wait a few seconds...\n",
      "[codecarbon INFO @ 23:23:15] Energy consumed for RAM : 0.000000 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 23:23:15] Energy consumed for all CPUs : 0.000000 kWh. Total CPU Power : 5.0 W\n",
      "[codecarbon INFO @ 23:23:15] 0.000001 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 23:23:15] Done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "initialized_class = LocalHMM(l_dataset)\n",
    "model = compute_emissions(initialized_class.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 23:23:27] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 23:23:27] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 23:23:27] No GPU found.\n",
      "[codecarbon INFO @ 23:23:27] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 23:23:27] No CPU tracking mode found. Falling back on CPU constant mode.\n",
      "[codecarbon INFO @ 23:23:27] CPU Model on constant consumption mode: Apple M1\n",
      "[codecarbon INFO @ 23:23:27] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 23:23:27]   Platform system: macOS-13.5.2-arm64-arm-64bit\n",
      "[codecarbon INFO @ 23:23:27]   Python version: 3.11.6\n",
      "[codecarbon INFO @ 23:23:27]   CodeCarbon version: 2.3.1\n",
      "[codecarbon INFO @ 23:23:27]   Available RAM : 16.000 GB\n",
      "[codecarbon INFO @ 23:23:27]   CPU count: 8\n",
      "[codecarbon INFO @ 23:23:27]   CPU model: Apple M1\n",
      "[codecarbon INFO @ 23:23:27]   GPU count: None\n",
      "[codecarbon INFO @ 23:23:27]   GPU model: None\n",
      "[codecarbon INFO @ 23:23:31] \n",
      "Graceful stopping: collecting and writing information.\n",
      "Please wait a few seconds...\n",
      "[codecarbon INFO @ 23:23:31] Energy consumed for RAM : 0.000004 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 23:23:31] Energy consumed for all CPUs : 0.000003 kWh. Total CPU Power : 5.0 W\n",
      "[codecarbon INFO @ 23:23:31] 0.000008 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 23:23:31] Done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = compute_emissions(model.predict, l_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When this model is run in an Apple M1 CPU model without any usage of GPUs, the summarised metrics are in the table below:\n",
    "\n",
    "|                                       | Training      | Predict       |\n",
    "|---------------------------------------|---------------|---------------|\n",
    "| Energy consumed for RAM               | 0.00 kWh      | 0.000004 kWh  |\n",
    "| Energy consumed for all CPUs          | 0.00 kWh      | 0.000003 kWh  |\n",
    "| Electricity used since the beginning  | 0.000001 kWh  | 0.000008      |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As can be seen, our model's consumption - in the datasets we have used - is mostly negligible.\n",
    "* Nonetheless, we can affirm that prediction is more expensive than training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
